{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /Users/studybuggy/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/studybuggy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/studybuggy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/studybuggy/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/studybuggy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import json\n",
    "import copy\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "from typing import Any\n",
    "PATH_TO_UNTOKENIZED_JSON = \"../data/shuffled_untokenized_article_swift_data.json\"\n",
    "PATH_TO_CSV_OUTPUT = \"../sentiment_analysis/pos_tag_sentiment_analysis.csv\"\n",
    "PATH_TO_JSON_OUTPUT = \"../sentiment_analysis/pos_tag_sentiment_analysis.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "STOP_WORDS.add(\"n't\")\n",
    "STOP_WORDS.add(\"'s\")\n",
    "PUNCTUATION = set(list(string.punctuation))\n",
    "with open(PATH_TO_UNTOKENIZED_JSON, 'r') as f:\n",
    "    json_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_copy = copy.deepcopy(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penn_to_wn(tag):\n",
    "    \"\"\"\n",
    "    Convert between the PennTreebank tags to simple Wordnet tags\n",
    "    \"\"\"\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(N:int, nt:int):\n",
    "    return math.log(N/nt)\n",
    "\n",
    "def idf_smooth(N: int, nt: int):\n",
    "    return math.log(N/(1+nt)) + 1\n",
    "\n",
    "\n",
    "def compute_doc_tf(doc_words:list)-> dict[str, float]:\n",
    "    doc_word_counts = Counter(doc_words)\n",
    "    total_count = doc_word_counts.total()\n",
    "    doc_tf = dict(doc_word_counts)\n",
    "    \n",
    "    for w,c in doc_tf.items():\n",
    "        doc_word_counts[w] = c/total_count\n",
    "    \n",
    "    return doc_tf\n",
    "\n",
    "\n",
    "def compute_all_idf(all_tf: list[dict[Any, float]]) -> dict[str, float]:\n",
    "    N = len(all_tf)\n",
    "    \n",
    "    # Get all the unique terms through all the articles\n",
    "    all_terms = [list(doc_tf.keys()) for doc_tf in all_tf]\n",
    "    all_terms = set(sum(all_terms, start=[]))\n",
    "    \n",
    "    # create idf to be returned\n",
    "    idf = dict[tuple[str], float]()\n",
    "    \n",
    "    # loop through all unique terms\n",
    "    for term in all_terms:\n",
    "        # start counting how many documents contain this word\n",
    "        nt = 0\n",
    "        for doc in all_tf:\n",
    "            if term in doc:\n",
    "                nt += 1\n",
    "        idf[term] = idf_smooth(N, nt)\n",
    "    \n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_articles_tf_idf(articles_info: list[dict]):\n",
    "    for article in articles_info:\n",
    "        content: str = article['content']\n",
    "        \n",
    "        # replace all punctuation and random characters with a space\n",
    "        # we do this to clean stop words and random characters since we care more\n",
    "        # about the content of the articles\n",
    "        content = re.sub(r'/n', '\\n', content)\n",
    "        content = re.sub(r'[^a-zA-Z0-9]', ' ', content)\n",
    "        \n",
    "        # tokenize content from articles using nltk tokenize\n",
    "        # We use tweet tokenizer since it provides better tokenization\n",
    "        terms = word_tokenize(content)\n",
    "        pos_terms = pos_tag(terms)\n",
    "        # remove stop words from terms\n",
    "        pos_terms = [pos_t for pos_t in pos_terms if pos_t[0].lower() not in STOP_WORDS]\n",
    "        \n",
    "        # store tokenized content\n",
    "        article['tokenized-pos-content'] = pos_terms\n",
    "        \n",
    "        # store the term frequencies\n",
    "        article['term-frequencies'] = compute_doc_tf(pos_terms)\n",
    "    \n",
    "    # compute the idf for all terms existing in every documents\n",
    "    all_tf = [article['term-frequencies'] for article in articles_info]\n",
    "    all_idf = compute_all_idf(all_tf)\n",
    "    \n",
    "    # compute tf-idf\n",
    "    for article in articles_info:\n",
    "        # get the term frequencies \n",
    "        doc_tf = article['term-frequencies']\n",
    "        \n",
    "        # multiply every term frequency with their idf score\n",
    "        doc_tf_idf = {pos_term: tf * all_idf[pos_term] for pos_term, tf in doc_tf.items()}\n",
    "        article['tf-idf'] = doc_tf_idf\n",
    "    \n",
    "\n",
    "\n",
    "compute_articles_tf_idf(json_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sentiment(tf_idf : dict[tuple[str], float], top_words:int = None) -> (float, dict[str, float]):\n",
    "\n",
    "    # use tweet tokenizer to remove contraction words as well\n",
    "    tweet_tokenizer = TweetTokenizer()\n",
    "    tfidf_items = list(tf_idf.items())\n",
    "    \n",
    "    tfidf_items.sort(key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    # create word lemmatizer to be used for getting meaning out of words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    tfidf_sentiment = 0.0\n",
    "    words = []\n",
    "    for word_postag, tfidf_score in tfidf_items:\n",
    "        word, tag = word_postag\n",
    "        # stop if we have computed the right amount of words\n",
    "        if (top_words is not None and len(words) >= top_words):\n",
    "            break\n",
    "        # # convert tag to wornet tag\n",
    "        # # make sure we keep nouns, adjectives, adverbs and verbs only\n",
    "        wn_tag = penn_to_wn(tag)\n",
    "        if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV, wn.VERB):\n",
    "            continue\n",
    "        \n",
    "        # create a lemma to represent the word's meaning\n",
    "        lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "        if not lemma:\n",
    "            continue\n",
    "        \n",
    "        # find synonym words representing the meaning the best from lemma\n",
    "        # and grammatical position of the word\n",
    "        synsets = wn.synsets(lemma, pos=wn_tag)\n",
    "        if not synsets:\n",
    "            continue\n",
    "\n",
    "        # Take the first sense, the most commonly used sense\n",
    "        synset = synsets[0]\n",
    "        # Get sentiment analysis of first sense word\n",
    "        swn_synset = swn.senti_synset(synset.name())\n",
    "\n",
    "        # calculate the positive vs negative score\n",
    "        word_sentiment = swn_synset.pos_score() - swn_synset.neg_score()\n",
    "        tfidf_sentiment += (tfidf_score * word_sentiment)\n",
    "        \n",
    "        # calculate the token counts, this can be used to get an avg of sentiment\n",
    "        # for each non stopword token in the article\n",
    "        words.append((word_postag, word_sentiment))\n",
    "    \n",
    "    top_lemmatized_words = {word_postag[0]:{'pos-tag':word_postag[1], 'tfidf-senti-score':tf_idf[word_postag] * sentiment,} for word_postag, sentiment in words}\n",
    "    \n",
    "    \n",
    "    return (tfidf_sentiment, top_lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sentiment_scores(json_data):\n",
    "    # compute the sentiment scores and store in json data\n",
    "    for article in json_data:\n",
    "        sentiment, top_lemmatized_words = compute_sentiment(article['tf-idf'], top_words=10)\n",
    "        article['total-sentiment-score'] = sentiment\n",
    "        article['top-10-lemmatized-words'] = top_lemmatized_words\n",
    "        \n",
    "        # reformat json for term frequency and tf-idf\n",
    "        term_frequencies:list[dict[str, Any]]  = list()\n",
    "        for term_pos_tag, freq in article['term-frequencies'].items():\n",
    "            term, pos_tag = term_pos_tag\n",
    "            term_frequencies.append(dict(word=term, tag=pos_tag, freq=freq))\n",
    "        article['term-frequencies'] = term_frequencies\n",
    "        \n",
    "        tf_idf : list[dict[str, Any]] = list()\n",
    "        for term_pos_tag, tfidf_score in article['tf-idf'].items():\n",
    "            term, pos_tag = term_pos_tag\n",
    "            tf_idf.append(dict(word=term, tag=pos_tag, score=tfidf_score))\n",
    "        article['tf-idf'] = tf_idf\n",
    "    \n",
    "        \n",
    "compute_sentiment_scores(json_copy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>source</th>\n",
       "      <th>category</th>\n",
       "      <th>country</th>\n",
       "      <th>published_at</th>\n",
       "      <th>isPriority</th>\n",
       "      <th>hasMain</th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>total-sentiment-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Victor Barbosa, Yardbarker</td>\n",
       "      <td>Mark Cuban wants to introduce Taylor Swift to ...</td>\n",
       "      <td>If Taylor Swift's much-rumored romance with Ka...</td>\n",
       "      <td>https://www.yardbarker.com/nba/articles/mark_c...</td>\n",
       "      <td>Yardbarker</td>\n",
       "      <td>sports</td>\n",
       "      <td>us</td>\n",
       "      <td>2023-09-28T19:44:18+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>If Taylor Swift's much-rumored romance with K...</td>\n",
       "      <td>2.244153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hugh McIntyre, Contributor</td>\n",
       "      <td>Taylor Swift Becomes The First Woman To Hit A ...</td>\n",
       "      <td>August 2023 has turned out to be perhaps Swift...</td>\n",
       "      <td>https://www.forbes.com/sites/hughmcintyre/2023...</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>general</td>\n",
       "      <td>us</td>\n",
       "      <td>2023-08-29T17:42:14+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>US singer-songwriter Taylor Swift poses on the...</td>\n",
       "      <td>7.401537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jonah Valdez</td>\n",
       "      <td>Travis Kelce's ex-girlfriend says she's gettin...</td>\n",
       "      <td>Travis Kelce's ex-girlfriend Maya Benberry sai...</td>\n",
       "      <td>https://www.latimes.com/entertainment-arts/sto...</td>\n",
       "      <td>latimes</td>\n",
       "      <td>general</td>\n",
       "      <td>us</td>\n",
       "      <td>2023-09-30T01:42:09+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>Travis Kelce’s former girlfriend, Maya Benberr...</td>\n",
       "      <td>17.387883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TMZ Staff</td>\n",
       "      <td>Travis Kelce Arrives In Argentina Ahead of Tay...</td>\n",
       "      <td>Travis Kelce has touched down in Argentina -- ...</td>\n",
       "      <td>https://www.tmz.com/2023/11/10/travis-kelce-ar...</td>\n",
       "      <td>TMZ</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>us</td>\n",
       "      <td>2023-11-10T18:15:59+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>update/n11:54 AM PT -- Huge bummer for Tayvis ...</td>\n",
       "      <td>-5.706278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Areeba Basharat</td>\n",
       "      <td>‘Need Taylor Swift’: Moments After the Devasta...</td>\n",
       "      <td>The first day out on the Italian greens turned...</td>\n",
       "      <td>https://www.essentiallysports.com/golf-news-pg...</td>\n",
       "      <td>Essentially Sports</td>\n",
       "      <td>sports</td>\n",
       "      <td>us</td>\n",
       "      <td>2023-09-29T19:06:25+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>Follow Us/nvia Reuters/nGolf – The 2023 Ryder ...</td>\n",
       "      <td>9.628437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>TMZ Staff</td>\n",
       "      <td>Travis Kelce Opens Up About Taylor Swift Relat...</td>\n",
       "      <td>Travis Kelce is opening up about the one thing...</td>\n",
       "      <td>https://www.tmz.com/2023/09/27/travis-kelce-ta...</td>\n",
       "      <td>TMZ</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>us</td>\n",
       "      <td>2023-09-27T13:32:19+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>495</td>\n",
       "      <td>Travis Kelce is opening up about the one thing...</td>\n",
       "      <td>7.650970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Mary Whitfill Roeloffs, Forbes Staff</td>\n",
       "      <td>Taylor Swift’s ‘Eras Tour’ Film Rakes In Recor...</td>\n",
       "      <td>A film documenting Taylor Swift’s megatour ear...</td>\n",
       "      <td>https://www.forbes.com/sites/maryroeloffs/2023...</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>general</td>\n",
       "      <td>us</td>\n",
       "      <td>2023-10-16T18:29:08+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>496</td>\n",
       "      <td>Taylor Swift’s concert film earned $92.8 milli...</td>\n",
       "      <td>-1.939834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Audrey Rock</td>\n",
       "      <td>David Beckham Addresses ‘Noise’ Surrounding Ta...</td>\n",
       "      <td>As speculation about Taylor's romance with the...</td>\n",
       "      <td>https://hollywoodlife.com/2023/10/03/david-bec...</td>\n",
       "      <td>hollywoodlife</td>\n",
       "      <td>general</td>\n",
       "      <td>us</td>\n",
       "      <td>2023-10-03T20:45:38+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>497</td>\n",
       "      <td>\\n\\t\\t\\t\\tAs speculation about Taylor's romanc...</td>\n",
       "      <td>18.999955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>None</td>\n",
       "      <td>Taylor Swift enters her football era and break...</td>\n",
       "      <td>Taylor Swift enters her football era and break...</td>\n",
       "      <td>https://www.npr.org/2023/09/26/1201849542/tayl...</td>\n",
       "      <td>wnyc</td>\n",
       "      <td>general</td>\n",
       "      <td>us</td>\n",
       "      <td>2023-09-26T20:28:02+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>498</td>\n",
       "      <td>By /n\\n\\n      Mia Venkat\\n    \\n/n, /n\\n\\n   ...</td>\n",
       "      <td>2.886523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Josh Levin and Stefan Fatsis</td>\n",
       "      <td>The NFL Media Needs a Better List of Taylor Sw...</td>\n",
       "      <td>No more cheer captains, blank spaces, and wild...</td>\n",
       "      <td>https://slate.com/podcasts/hang-up-and-listen/...</td>\n",
       "      <td>Slate Magazine</td>\n",
       "      <td>general</td>\n",
       "      <td>us</td>\n",
       "      <td>2023-10-02T23:31:57+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>499</td>\n",
       "      <td>Slate’s sports podcast on “Tayvis,” the Damian...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   author  \\\n",
       "0              Victor Barbosa, Yardbarker   \n",
       "1              Hugh McIntyre, Contributor   \n",
       "2                            Jonah Valdez   \n",
       "3                               TMZ Staff   \n",
       "4                         Areeba Basharat   \n",
       "..                                    ...   \n",
       "495                             TMZ Staff   \n",
       "496  Mary Whitfill Roeloffs, Forbes Staff   \n",
       "497                           Audrey Rock   \n",
       "498                                  None   \n",
       "499          Josh Levin and Stefan Fatsis   \n",
       "\n",
       "                                                 title  \\\n",
       "0    Mark Cuban wants to introduce Taylor Swift to ...   \n",
       "1    Taylor Swift Becomes The First Woman To Hit A ...   \n",
       "2    Travis Kelce's ex-girlfriend says she's gettin...   \n",
       "3    Travis Kelce Arrives In Argentina Ahead of Tay...   \n",
       "4    ‘Need Taylor Swift’: Moments After the Devasta...   \n",
       "..                                                 ...   \n",
       "495  Travis Kelce Opens Up About Taylor Swift Relat...   \n",
       "496  Taylor Swift’s ‘Eras Tour’ Film Rakes In Recor...   \n",
       "497  David Beckham Addresses ‘Noise’ Surrounding Ta...   \n",
       "498  Taylor Swift enters her football era and break...   \n",
       "499  The NFL Media Needs a Better List of Taylor Sw...   \n",
       "\n",
       "                                           description  \\\n",
       "0    If Taylor Swift's much-rumored romance with Ka...   \n",
       "1    August 2023 has turned out to be perhaps Swift...   \n",
       "2    Travis Kelce's ex-girlfriend Maya Benberry sai...   \n",
       "3    Travis Kelce has touched down in Argentina -- ...   \n",
       "4    The first day out on the Italian greens turned...   \n",
       "..                                                 ...   \n",
       "495  Travis Kelce is opening up about the one thing...   \n",
       "496  A film documenting Taylor Swift’s megatour ear...   \n",
       "497  As speculation about Taylor's romance with the...   \n",
       "498  Taylor Swift enters her football era and break...   \n",
       "499  No more cheer captains, blank spaces, and wild...   \n",
       "\n",
       "                                                   url              source  \\\n",
       "0    https://www.yardbarker.com/nba/articles/mark_c...          Yardbarker   \n",
       "1    https://www.forbes.com/sites/hughmcintyre/2023...              Forbes   \n",
       "2    https://www.latimes.com/entertainment-arts/sto...             latimes   \n",
       "3    https://www.tmz.com/2023/11/10/travis-kelce-ar...                 TMZ   \n",
       "4    https://www.essentiallysports.com/golf-news-pg...  Essentially Sports   \n",
       "..                                                 ...                 ...   \n",
       "495  https://www.tmz.com/2023/09/27/travis-kelce-ta...                 TMZ   \n",
       "496  https://www.forbes.com/sites/maryroeloffs/2023...              Forbes   \n",
       "497  https://hollywoodlife.com/2023/10/03/david-bec...       hollywoodlife   \n",
       "498  https://www.npr.org/2023/09/26/1201849542/tayl...                wnyc   \n",
       "499  https://slate.com/podcasts/hang-up-and-listen/...      Slate Magazine   \n",
       "\n",
       "          category country               published_at  isPriority  hasMain  \\\n",
       "0           sports      us  2023-09-28T19:44:18+00:00       False    False   \n",
       "1          general      us  2023-08-29T17:42:14+00:00        True     True   \n",
       "2          general      us  2023-09-30T01:42:09+00:00        True     True   \n",
       "3    entertainment      us  2023-11-10T18:15:59+00:00        True     True   \n",
       "4           sports      us  2023-09-29T19:06:25+00:00       False     True   \n",
       "..             ...     ...                        ...         ...      ...   \n",
       "495  entertainment      us  2023-09-27T13:32:19+00:00        True     True   \n",
       "496        general      us  2023-10-16T18:29:08+00:00        True     True   \n",
       "497        general      us  2023-10-03T20:45:38+00:00       False     True   \n",
       "498        general      us  2023-09-26T20:28:02+00:00        True     True   \n",
       "499        general      us  2023-10-02T23:31:57+00:00       False     True   \n",
       "\n",
       "      id                                            content  \\\n",
       "0      0   If Taylor Swift's much-rumored romance with K...   \n",
       "1      1  US singer-songwriter Taylor Swift poses on the...   \n",
       "2      2  Travis Kelce’s former girlfriend, Maya Benberr...   \n",
       "3      3  update/n11:54 AM PT -- Huge bummer for Tayvis ...   \n",
       "4      4  Follow Us/nvia Reuters/nGolf – The 2023 Ryder ...   \n",
       "..   ...                                                ...   \n",
       "495  495  Travis Kelce is opening up about the one thing...   \n",
       "496  496  Taylor Swift’s concert film earned $92.8 milli...   \n",
       "497  497  \\n\\t\\t\\t\\tAs speculation about Taylor's romanc...   \n",
       "498  498  By /n\\n\\n      Mia Venkat\\n    \\n/n, /n\\n\\n   ...   \n",
       "499  499  Slate’s sports podcast on “Tayvis,” the Damian...   \n",
       "\n",
       "     total-sentiment-score  \n",
       "0                 2.244153  \n",
       "1                 7.401537  \n",
       "2                17.387883  \n",
       "3                -5.706278  \n",
       "4                 9.628437  \n",
       "..                     ...  \n",
       "495               7.650970  \n",
       "496              -1.939834  \n",
       "497              18.999955  \n",
       "498               2.886523  \n",
       "499               0.000000  \n",
       "\n",
       "[500 rows x 13 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create csv file\n",
    "def json_to_df(json_data):\n",
    "    \n",
    "    columns = list(json_data[0].keys())\n",
    "    columns.remove('top-10-lemmatized-words')\n",
    "    columns.remove('tf-idf')\n",
    "    columns.remove('term-frequencies')\n",
    "    columns.remove('tokenized-pos-content')\n",
    "    dict_df = {c:[] for c in columns}\n",
    "    \n",
    "    for article in json_data:\n",
    "        for col in columns:\n",
    "            dict_df[col].append(article[col])\n",
    "    \n",
    "    return pd.DataFrame.from_dict(dict_df)\n",
    "\n",
    "df = json_to_df(json_copy)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_TO_JSON_OUTPUT, 'w') as f:\n",
    "    json.dump(json_copy, f, indent=2)\n",
    "\n",
    "with open(PATH_TO_CSV_OUTPUT, 'w') as f:\n",
    "    df.to_csv(f, index=True)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP370-H4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
